{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ioachimlihor/Master/An1/Sem1/NLPFundLab/nlp/lib64/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../notebooks/scaler.pkl\", \"rb\") as f:\n",
    "    scaller = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ioachimlihor/Master/An1/Sem1/NLPFundLab/nlp/lib64/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/pytorch_fakerobertmodel_title_conv.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import models.config\n",
    "\n",
    "from models.model import FakeRoBERTModel\n",
    "\n",
    "model = FakeRoBERTModel()\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "print(models.config.MODEL_PATH)\n",
    "model.load_state_dict(torch.load(\"../models/pytorch_fakerobertmodel_content.bin\"))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Peste jumătate dintre pacienții diagnosticați cu Covid-19 au dezvoltat anomalii ale funcțiilor cardiace, potrivit unui studiu efectuat de Fundația Britanică pentru Boli Cardiace din cadrul Universității Edinburgh.\n",
      "[[0.40406257]]\n",
      "Predicting...\n",
      "Centrul INFOTRAFIC din Inspectoratul General al Poliției Române informează că din cauza unui accident rutier în care au fost implicate un autotren și un autoturism, circulația rutieră este blocată pe DN12 Sfântu Gheorghe - Chilieni (km. 7+900m). Traficul este blocat pentru aproximativ 45 de minute.\n",
      "[[0.5384946]]\n",
      "Predicting...\n",
      "Te-ai săturat să te trezești odihnit, la ce oră vrei tu? Are ISU grijă! Reporterii TNR au obținut deja cele 10 mesaje de test pe care sistemul de avertizare le va difuza în acest weekend.\n",
      "[[0.08946845]]\n"
     ]
    }
   ],
   "source": [
    "from models.predict_model import predict\n",
    "\n",
    "for content in [\n",
    "    \"Peste jumătate dintre pacienții diagnosticați cu Covid-19 au dezvoltat anomalii ale funcțiilor cardiace, potrivit unui studiu efectuat de Fundația Britanică pentru Boli Cardiace din cadrul Universității Edinburgh.\",\n",
    "    \"Centrul INFOTRAFIC din Inspectoratul General al Poliției Române informează că din cauza unui accident rutier în care au fost implicate un autotren și un autoturism, circulația rutieră este blocată pe DN12 Sfântu Gheorghe - Chilieni (km. 7+900m). Traficul este blocat pentru aproximativ 45 de minute.\",\n",
    "    \"Te-ai săturat să te trezești odihnit, la ce oră vrei tu? Are ISU grijă! Reporterii TNR au obținut deja cele 10 mesaje de test pe care sistemul de avertizare le va difuza în acest weekend.\"\n",
    "]:\n",
    "    print(\"Predicting...\")\n",
    "    print(content)\n",
    "    outputs = predict(\n",
    "        text=content,\n",
    "        model=model,\n",
    "        tokenizer=models.config.TOKENIZER,\n",
    "        scaler=scaller,\n",
    "        device=device,\n",
    "    )\n",
    "    print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Peste jumătate dintre pacienții cu coronavirus au dezvoltat disfuncții ale inimii.\n",
      "[[0.32395276]]\n",
      "Predicting...\n",
      "Covasna. Circulație oprită între Sfântu Gheorghe și Brașov (DN 12), la Chilieni, din cauza unui accident între un TIR și o mașină.\n",
      "[[0.3544454]]\n",
      "Predicting...\n",
      "10 mesaje de la Ro-Alert pe care sigur le vei primi weekendul ăsta\n",
      "[[0.30516014]]\n"
     ]
    }
   ],
   "source": [
    "from models.predict_model import predict\n",
    "\n",
    "for title in [\n",
    "    \"Peste jumătate dintre pacienții cu coronavirus au dezvoltat disfuncții ale inimii.\",\n",
    "    \"Covasna. Circulație oprită între Sfântu Gheorghe și Brașov (DN 12), la Chilieni, din cauza unui accident între un TIR și o mașină.\",\n",
    "    \"10 mesaje de la Ro-Alert pe care sigur le vei primi weekendul ăsta\"\n",
    "]:\n",
    "    print(\"Predicting...\")\n",
    "    print(title)\n",
    "    outputs = predict(\n",
    "        text=title,\n",
    "        model=model,\n",
    "        tokenizer=models.config.TOKENIZER,\n",
    "        scaler=scaller,\n",
    "        device=device,\n",
    "    )\n",
    "    print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5899411]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaller.inverse_trainsform(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(cpu)\n",
    "torch.save(model.state_dict(), \"../models/pytorch_fakerobertmodel_content_cpu.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/pytorch_fakerobertmodel_title.bin\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import src.models.config\n",
    "\n",
    "from src.models.model import FakeRoBERTModel\n",
    "\n",
    "model = FakeRoBERTModel()\n",
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "model = FakeRoBERTModel()\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "print(src.models.config.MODEL_PATH)\n",
    "model.load_state_dict(torch.load(\"../cluster_results/pytorch_fakerobertmodel_title.bin\"))\n",
    "model = model.to(cpu)\n",
    "torch.save(model.state_dict(), \"../cluster/trained_models/pytorch_fakerobertmodel_title_cpu.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be4b212abb4d94a783b217aa1fb356a848339ff4bc045610c6de9188f4152310"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
