{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "class FakeRoBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FakeRoBERTModel, self).__init__()\n",
    "        # embedding\n",
    "        self.bert = transformers.AutoModel.from_pretrained(\n",
    "            \"dumitrescustefan/bert-base-romanian-cased-v1\"\n",
    "        )\n",
    "\n",
    "        # first convolutional layers\n",
    "        self.conv1_2 = nn.Conv1d(768, 512, kernel_size=1, stride=1, padding=0)\n",
    "        self.drop1_3 = nn.Dropout(p=0.2)\n",
    "        self.pool1_4 = nn.MaxPool1d(kernel_size=1, stride=2, padding=0)\n",
    "\n",
    "        # second convolutional layers\n",
    "        self.conv1_5 = nn.Conv1d(512, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.drop1_5 = nn.Dropout(p=0.2)\n",
    "        self.pool1_5 = nn.MaxPool1d(kernel_size=1, stride=2, padding=0)\n",
    "        self.conv1_6 = nn.Conv1d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.drop1_6 = nn.Dropout(p=0.2)\n",
    "        self.pool1_6 = nn.MaxPool1d(kernel_size=1, stride=2, padding=0)\n",
    "\n",
    "        # flatten\n",
    "        self.flatt_7 = nn.Flatten(1, -1)\n",
    "\n",
    "        # dense layers\n",
    "        self.dense1_8 = nn.Linear(64, 32)\n",
    "        self.dense1_9 = nn.Linear(32, 1)\n",
    "\n",
    "        self.dense_1 = nn.Linear(768, 256)\n",
    "        self.dense_3 = nn.Linear(256, 32)\n",
    "        self.dense_4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "        # x, y = pooled_output.size()\n",
    "        # pooled_output = torch.reshape(pooled_output, (x, y, 1))\n",
    "\n",
    "        # conv1_2 = self.pool1_4(self.drop1_3(torch.relu(self.conv1_2(pooled_output))))\n",
    "        # x = conv1_2\n",
    "        # x = self.pool1_5(self.drop1_5(F.relu(self.conv1_5(x))))\n",
    "        # x = self.pool1_6(self.drop1_6(F.relu(self.conv1_6(x))))\n",
    "        # x = self.flatt_7(x)\n",
    "        # x = self.dense1_8(x)\n",
    "\n",
    "        x = self.drop1_6(pooled_output)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.dense_4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = FakeRoBERTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_PATH = \"dumitrescustefan/bert-base-romanian-cased-v1\"\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    max_len: int = 512\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "        \"Salutare, lume!\",\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding=\"longest\",\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    ids = encoded_text[\"input_ids\"]\n",
    "    mask = encoded_text[\"attention_mask\"]\n",
    "    token_type_ids = encoded_text[\"token_type_ids\"]\n",
    "\n",
    "    padding_length = max_len - len(ids)\n",
    "    ids = ids + ([0] * padding_length)\n",
    "    mask = mask + ([0] * padding_length)\n",
    "    token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "\n",
    "    ids = torch.tensor([ids], dtype=torch.long)\n",
    "    mask = torch.tensor([mask], dtype=torch.long)\n",
    "    token_type_ids = torch.tensor([token_type_ids], dtype=torch.long)\n",
    "\n",
    "    ids = ids.to(device, dtype=torch.long)\n",
    "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "    mask = mask.to(device, dtype=torch.long)\n",
    "\n",
    "    yhat = model(input_ids=ids, attention_mask=mask, token_type_ids=token_type_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FakeRoBERT.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(yhat[0], params=dict(list(model.named_parameters()))).render(\"FakeRoBERT\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ioachimlihor/Licenta/Project/licenta/licenta-env/lib64/python3.10/site-packages/torch/onnx/symbolic_helper.py:324: UserWarning: Type cannot be inferred, which might cause exported graph to produce incorrect results.\n",
      "  warnings.warn(\"Type cannot be inferred, which might cause exported graph to produce incorrect results.\")\n",
      "/home/ioachimlihor/Licenta/Project/licenta/licenta-env/lib64/python3.10/site-packages/torch/onnx/symbolic_opset9.py:1672: UserWarning: Dropout is a training op and should not be exported in inference mode. For inference, make sure to call eval() on the model and to export it with param training=False.\n",
      "  warnings.warn(\"Dropout is a training op and should not be exported in inference mode. \"\n"
     ]
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "graph = hl.build_graph(model, args=(ids, mask, token_type_ids), transforms=[])\n",
    "graph.theme = hl.graph.THEMES[\"blue\"].copy()\n",
    "graph.save(\"FakeRoBERT_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = ['Sentence']\n",
    "output_names = ['yhat']\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (ids, mask, token_type_ids),\n",
    "    \"rnn.onnx\",\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %Sentence[INT64, 1x512]\n",
      "  %attention_mask[INT64, 1x512]\n",
      "  %input.3[INT64, 1x512]\n",
      ") initializers (\n",
      "  %bert.embeddings.word_embeddings.weight[FLOAT, 50000x768]\n",
      "  %bert.embeddings.position_embeddings.weight[FLOAT, 512x768]\n",
      "  %bert.embeddings.token_type_embeddings.weight[FLOAT, 2x768]\n",
      "  %bert.embeddings.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.embeddings.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.0.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.1.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.2.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.3.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.4.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.5.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.6.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.7.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.8.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.9.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.10.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.11.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.pooler.dense.weight[FLOAT, 768x768]\n",
      "  %bert.pooler.dense.bias[FLOAT, 768]\n",
      "  %dense_1.weight[FLOAT, 256x768]\n",
      "  %dense_1.bias[FLOAT, 256]\n",
      "  %dense_3.weight[FLOAT, 32x256]\n",
      "  %dense_3.bias[FLOAT, 32]\n",
      "  %dense_4.weight[FLOAT, 1x32]\n",
      "  %dense_4.bias[FLOAT, 1]\n",
      "  %onnx::Gather_1427[INT64, 1x512]\n",
      "  %onnx::MatMul_1428[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1429[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1434[INT64, 4]\n",
      "  %onnx::MatMul_1435[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1440[INT64, 4]\n",
      "  %onnx::Reshape_1445[INT64, 4]\n",
      "  %onnx::Reshape_1449[INT64, 3]\n",
      "  %onnx::MatMul_1450[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1451[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1452[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1453[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1454[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1459[INT64, 4]\n",
      "  %onnx::MatMul_1460[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1465[INT64, 4]\n",
      "  %onnx::Reshape_1470[INT64, 4]\n",
      "  %onnx::Reshape_1474[INT64, 3]\n",
      "  %onnx::MatMul_1475[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1476[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1477[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1478[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1479[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1484[INT64, 4]\n",
      "  %onnx::MatMul_1485[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1490[INT64, 4]\n",
      "  %onnx::Reshape_1495[INT64, 4]\n",
      "  %onnx::Reshape_1499[INT64, 3]\n",
      "  %onnx::MatMul_1500[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1501[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1502[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1503[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1504[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1509[INT64, 4]\n",
      "  %onnx::MatMul_1510[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1515[INT64, 4]\n",
      "  %onnx::Reshape_1520[INT64, 4]\n",
      "  %onnx::Reshape_1524[INT64, 3]\n",
      "  %onnx::MatMul_1525[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1526[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1527[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1528[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1529[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1534[INT64, 4]\n",
      "  %onnx::MatMul_1535[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1540[INT64, 4]\n",
      "  %onnx::Reshape_1545[INT64, 4]\n",
      "  %onnx::Reshape_1549[INT64, 3]\n",
      "  %onnx::MatMul_1550[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1551[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1552[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1553[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1554[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1559[INT64, 4]\n",
      "  %onnx::MatMul_1560[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1565[INT64, 4]\n",
      "  %onnx::Reshape_1570[INT64, 4]\n",
      "  %onnx::Reshape_1574[INT64, 3]\n",
      "  %onnx::MatMul_1575[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1576[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1577[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1578[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1579[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1584[INT64, 4]\n",
      "  %onnx::MatMul_1585[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1590[INT64, 4]\n",
      "  %onnx::Reshape_1595[INT64, 4]\n",
      "  %onnx::Reshape_1599[INT64, 3]\n",
      "  %onnx::MatMul_1600[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1601[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1602[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1603[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1604[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1609[INT64, 4]\n",
      "  %onnx::MatMul_1610[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1615[INT64, 4]\n",
      "  %onnx::Reshape_1620[INT64, 4]\n",
      "  %onnx::Reshape_1624[INT64, 3]\n",
      "  %onnx::MatMul_1625[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1626[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1627[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1628[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1629[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1634[INT64, 4]\n",
      "  %onnx::MatMul_1635[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1640[INT64, 4]\n",
      "  %onnx::Reshape_1645[INT64, 4]\n",
      "  %onnx::Reshape_1649[INT64, 3]\n",
      "  %onnx::MatMul_1650[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1651[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1652[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1653[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1654[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1659[INT64, 4]\n",
      "  %onnx::MatMul_1660[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1665[INT64, 4]\n",
      "  %onnx::Reshape_1670[INT64, 4]\n",
      "  %onnx::Reshape_1674[INT64, 3]\n",
      "  %onnx::MatMul_1675[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1676[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1677[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1678[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1679[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1684[INT64, 4]\n",
      "  %onnx::MatMul_1685[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1690[INT64, 4]\n",
      "  %onnx::Reshape_1695[INT64, 4]\n",
      "  %onnx::Reshape_1699[INT64, 3]\n",
      "  %onnx::MatMul_1700[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1701[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1702[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1703[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1704[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1709[INT64, 4]\n",
      "  %onnx::MatMul_1710[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1715[INT64, 4]\n",
      "  %onnx::Reshape_1720[INT64, 4]\n",
      "  %onnx::Reshape_1724[INT64, 3]\n",
      "  %onnx::MatMul_1725[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1726[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1727[FLOAT, 3072x768]\n",
      ") {\n",
      "  %onnx::Unsqueeze_219 = Unsqueeze[axes = [1]](%attention_mask)\n",
      "  %onnx::Cast_220 = Unsqueeze[axes = [2]](%onnx::Unsqueeze_219)\n",
      "  %onnx::Sub_221 = Cast[to = 1](%onnx::Cast_220)\n",
      "  %onnx::Sub_222 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_223 = Sub(%onnx::Sub_222, %onnx::Sub_221)\n",
      "  %onnx::Mul_224 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_225 = Mul(%onnx::Mul_223, %onnx::Mul_224)\n",
      "  %onnx::Add_227 = Gather(%bert.embeddings.word_embeddings.weight, %Sentence)\n",
      "  %onnx::Add_228 = Gather(%bert.embeddings.token_type_embeddings.weight, %input.3)\n",
      "  %onnx::Add_229 = Add(%onnx::Add_227, %onnx::Add_228)\n",
      "  %onnx::Add_230 = Gather(%bert.embeddings.position_embeddings.weight, %onnx::Gather_1427)\n",
      "  %onnx::ReduceMean_231 = Add(%onnx::Add_229, %onnx::Add_230)\n",
      "  %onnx::Sub_232 = ReduceMean[axes = [-1]](%onnx::ReduceMean_231)\n",
      "  %onnx::Pow_233 = Sub(%onnx::ReduceMean_231, %onnx::Sub_232)\n",
      "  %onnx::Pow_234 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_235 = Pow(%onnx::Pow_233, %onnx::Pow_234)\n",
      "  %onnx::Add_236 = ReduceMean[axes = [-1]](%onnx::ReduceMean_235)\n",
      "  %onnx::Add_237 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_238 = Add(%onnx::Add_236, %onnx::Add_237)\n",
      "  %onnx::Div_239 = Sqrt(%onnx::Sqrt_238)\n",
      "  %onnx::Mul_240 = Div(%onnx::Pow_233, %onnx::Div_239)\n",
      "  %onnx::Add_241 = Mul(%onnx::Mul_240, %bert.embeddings.LayerNorm.weight)\n",
      "  %input.4 = Add(%onnx::Add_241, %bert.embeddings.LayerNorm.bias)\n",
      "  %onnx::Add_244 = MatMul(%input.4, %onnx::MatMul_1428)\n",
      "  %mixed_query_layer = Add(%bert.encoder.layer.0.attention.self.query.bias, %onnx::Add_244)\n",
      "  %onnx::Add_247 = MatMul(%input.4, %onnx::MatMul_1429)\n",
      "  %onnx::Reshape_248 = Add(%bert.encoder.layer.0.attention.self.key.bias, %onnx::Add_247)\n",
      "  %onnx::Transpose_258 = Reshape(%onnx::Reshape_248, %onnx::Reshape_1434)\n",
      "  %onnx::Add_260 = MatMul(%input.4, %onnx::MatMul_1435)\n",
      "  %onnx::Reshape_261 = Add(%bert.encoder.layer.0.attention.self.value.bias, %onnx::Add_260)\n",
      "  %onnx::Transpose_271 = Reshape(%onnx::Reshape_261, %onnx::Reshape_1440)\n",
      "  %onnx::MatMul_272 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_271)\n",
      "  %onnx::Transpose_282 = Reshape(%mixed_query_layer, %onnx::Reshape_1445)\n",
      "  %onnx::MatMul_283 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_282)\n",
      "  %onnx::MatMul_284 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_258)\n",
      "  %onnx::Div_285 = MatMul(%onnx::MatMul_283, %onnx::MatMul_284)\n",
      "  %onnx::Div_286 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_287 = Div(%onnx::Div_285, %onnx::Div_286)\n",
      "  %attention_scores = Add(%onnx::Add_287, %onnx::Add_225)\n",
      "  %input.8 = Softmax[axis = 3](%attention_scores)\n",
      "  %onnx::Transpose_290 = MatMul(%input.8, %onnx::MatMul_272)\n",
      "  %onnx::Reshape_291 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_290)\n",
      "  %onnx::MatMul_299 = Reshape(%onnx::Reshape_291, %onnx::Reshape_1449)\n",
      "  %onnx::Add_301 = MatMul(%onnx::MatMul_299, %onnx::MatMul_1450)\n",
      "  %input.12 = Add(%bert.encoder.layer.0.attention.output.dense.bias, %onnx::Add_301)\n",
      "  %input.16 = Add(%input.12, %input.4)\n",
      "  %onnx::Sub_304 = ReduceMean[axes = [-1]](%input.16)\n",
      "  %onnx::Pow_305 = Sub(%input.16, %onnx::Sub_304)\n",
      "  %onnx::Pow_306 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_307 = Pow(%onnx::Pow_305, %onnx::Pow_306)\n",
      "  %onnx::Add_308 = ReduceMean[axes = [-1]](%onnx::ReduceMean_307)\n",
      "  %onnx::Add_309 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_310 = Add(%onnx::Add_308, %onnx::Add_309)\n",
      "  %onnx::Div_311 = Sqrt(%onnx::Sqrt_310)\n",
      "  %onnx::Mul_312 = Div(%onnx::Pow_305, %onnx::Div_311)\n",
      "  %onnx::Add_313 = Mul(%onnx::Mul_312, %bert.encoder.layer.0.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_314 = Add(%onnx::Add_313, %bert.encoder.layer.0.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_316 = MatMul(%onnx::MatMul_314, %onnx::MatMul_1451)\n",
      "  %onnx::Div_317 = Add(%bert.encoder.layer.0.intermediate.dense.bias, %onnx::Add_316)\n",
      "  %onnx::Div_318 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_319 = Div(%onnx::Div_317, %onnx::Div_318)\n",
      "  %onnx::Add_320 = Erf(%onnx::Erf_319)\n",
      "  %onnx::Add_321 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_322 = Add(%onnx::Add_320, %onnx::Add_321)\n",
      "  %onnx::Mul_323 = Mul(%onnx::Div_317, %onnx::Mul_322)\n",
      "  %onnx::Mul_324 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_325 = Mul(%onnx::Mul_323, %onnx::Mul_324)\n",
      "  %onnx::Add_327 = MatMul(%onnx::MatMul_325, %onnx::MatMul_1452)\n",
      "  %input.20 = Add(%bert.encoder.layer.0.output.dense.bias, %onnx::Add_327)\n",
      "  %input.24 = Add(%input.20, %onnx::MatMul_314)\n",
      "  %onnx::Sub_330 = ReduceMean[axes = [-1]](%input.24)\n",
      "  %onnx::Pow_331 = Sub(%input.24, %onnx::Sub_330)\n",
      "  %onnx::Pow_332 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_333 = Pow(%onnx::Pow_331, %onnx::Pow_332)\n",
      "  %onnx::Add_334 = ReduceMean[axes = [-1]](%onnx::ReduceMean_333)\n",
      "  %onnx::Add_335 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_336 = Add(%onnx::Add_334, %onnx::Add_335)\n",
      "  %onnx::Div_337 = Sqrt(%onnx::Sqrt_336)\n",
      "  %onnx::Mul_338 = Div(%onnx::Pow_331, %onnx::Div_337)\n",
      "  %onnx::Add_339 = Mul(%onnx::Mul_338, %bert.encoder.layer.0.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_340 = Add(%onnx::Add_339, %bert.encoder.layer.0.output.LayerNorm.bias)\n",
      "  %onnx::Add_342 = MatMul(%onnx::MatMul_340, %onnx::MatMul_1453)\n",
      "  %mixed_query_layer.3 = Add(%bert.encoder.layer.1.attention.self.query.bias, %onnx::Add_342)\n",
      "  %onnx::Add_345 = MatMul(%onnx::MatMul_340, %onnx::MatMul_1454)\n",
      "  %onnx::Reshape_346 = Add(%bert.encoder.layer.1.attention.self.key.bias, %onnx::Add_345)\n",
      "  %onnx::Transpose_356 = Reshape(%onnx::Reshape_346, %onnx::Reshape_1459)\n",
      "  %onnx::Add_358 = MatMul(%onnx::MatMul_340, %onnx::MatMul_1460)\n",
      "  %onnx::Reshape_359 = Add(%bert.encoder.layer.1.attention.self.value.bias, %onnx::Add_358)\n",
      "  %onnx::Transpose_369 = Reshape(%onnx::Reshape_359, %onnx::Reshape_1465)\n",
      "  %onnx::MatMul_370 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_369)\n",
      "  %onnx::Transpose_380 = Reshape(%mixed_query_layer.3, %onnx::Reshape_1470)\n",
      "  %onnx::MatMul_381 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_380)\n",
      "  %onnx::MatMul_382 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_356)\n",
      "  %onnx::Div_383 = MatMul(%onnx::MatMul_381, %onnx::MatMul_382)\n",
      "  %onnx::Div_384 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_385 = Div(%onnx::Div_383, %onnx::Div_384)\n",
      "  %attention_scores.3 = Add(%onnx::Add_385, %onnx::Add_225)\n",
      "  %input.28 = Softmax[axis = 3](%attention_scores.3)\n",
      "  %onnx::Transpose_388 = MatMul(%input.28, %onnx::MatMul_370)\n",
      "  %onnx::Reshape_389 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_388)\n",
      "  %onnx::MatMul_397 = Reshape(%onnx::Reshape_389, %onnx::Reshape_1474)\n",
      "  %onnx::Add_399 = MatMul(%onnx::MatMul_397, %onnx::MatMul_1475)\n",
      "  %input.32 = Add(%bert.encoder.layer.1.attention.output.dense.bias, %onnx::Add_399)\n",
      "  %input.36 = Add(%input.32, %onnx::MatMul_340)\n",
      "  %onnx::Sub_402 = ReduceMean[axes = [-1]](%input.36)\n",
      "  %onnx::Pow_403 = Sub(%input.36, %onnx::Sub_402)\n",
      "  %onnx::Pow_404 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_405 = Pow(%onnx::Pow_403, %onnx::Pow_404)\n",
      "  %onnx::Add_406 = ReduceMean[axes = [-1]](%onnx::ReduceMean_405)\n",
      "  %onnx::Add_407 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_408 = Add(%onnx::Add_406, %onnx::Add_407)\n",
      "  %onnx::Div_409 = Sqrt(%onnx::Sqrt_408)\n",
      "  %onnx::Mul_410 = Div(%onnx::Pow_403, %onnx::Div_409)\n",
      "  %onnx::Add_411 = Mul(%onnx::Mul_410, %bert.encoder.layer.1.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_412 = Add(%onnx::Add_411, %bert.encoder.layer.1.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_414 = MatMul(%onnx::MatMul_412, %onnx::MatMul_1476)\n",
      "  %onnx::Div_415 = Add(%bert.encoder.layer.1.intermediate.dense.bias, %onnx::Add_414)\n",
      "  %onnx::Div_416 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_417 = Div(%onnx::Div_415, %onnx::Div_416)\n",
      "  %onnx::Add_418 = Erf(%onnx::Erf_417)\n",
      "  %onnx::Add_419 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_420 = Add(%onnx::Add_418, %onnx::Add_419)\n",
      "  %onnx::Mul_421 = Mul(%onnx::Div_415, %onnx::Mul_420)\n",
      "  %onnx::Mul_422 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_423 = Mul(%onnx::Mul_421, %onnx::Mul_422)\n",
      "  %onnx::Add_425 = MatMul(%onnx::MatMul_423, %onnx::MatMul_1477)\n",
      "  %input.40 = Add(%bert.encoder.layer.1.output.dense.bias, %onnx::Add_425)\n",
      "  %input.44 = Add(%input.40, %onnx::MatMul_412)\n",
      "  %onnx::Sub_428 = ReduceMean[axes = [-1]](%input.44)\n",
      "  %onnx::Pow_429 = Sub(%input.44, %onnx::Sub_428)\n",
      "  %onnx::Pow_430 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_431 = Pow(%onnx::Pow_429, %onnx::Pow_430)\n",
      "  %onnx::Add_432 = ReduceMean[axes = [-1]](%onnx::ReduceMean_431)\n",
      "  %onnx::Add_433 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_434 = Add(%onnx::Add_432, %onnx::Add_433)\n",
      "  %onnx::Div_435 = Sqrt(%onnx::Sqrt_434)\n",
      "  %onnx::Mul_436 = Div(%onnx::Pow_429, %onnx::Div_435)\n",
      "  %onnx::Add_437 = Mul(%onnx::Mul_436, %bert.encoder.layer.1.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_438 = Add(%onnx::Add_437, %bert.encoder.layer.1.output.LayerNorm.bias)\n",
      "  %onnx::Add_440 = MatMul(%onnx::MatMul_438, %onnx::MatMul_1478)\n",
      "  %mixed_query_layer.7 = Add(%bert.encoder.layer.2.attention.self.query.bias, %onnx::Add_440)\n",
      "  %onnx::Add_443 = MatMul(%onnx::MatMul_438, %onnx::MatMul_1479)\n",
      "  %onnx::Reshape_444 = Add(%bert.encoder.layer.2.attention.self.key.bias, %onnx::Add_443)\n",
      "  %onnx::Transpose_454 = Reshape(%onnx::Reshape_444, %onnx::Reshape_1484)\n",
      "  %onnx::Add_456 = MatMul(%onnx::MatMul_438, %onnx::MatMul_1485)\n",
      "  %onnx::Reshape_457 = Add(%bert.encoder.layer.2.attention.self.value.bias, %onnx::Add_456)\n",
      "  %onnx::Transpose_467 = Reshape(%onnx::Reshape_457, %onnx::Reshape_1490)\n",
      "  %onnx::MatMul_468 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_467)\n",
      "  %onnx::Transpose_478 = Reshape(%mixed_query_layer.7, %onnx::Reshape_1495)\n",
      "  %onnx::MatMul_479 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_478)\n",
      "  %onnx::MatMul_480 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_454)\n",
      "  %onnx::Div_481 = MatMul(%onnx::MatMul_479, %onnx::MatMul_480)\n",
      "  %onnx::Div_482 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_483 = Div(%onnx::Div_481, %onnx::Div_482)\n",
      "  %attention_scores.7 = Add(%onnx::Add_483, %onnx::Add_225)\n",
      "  %input.48 = Softmax[axis = 3](%attention_scores.7)\n",
      "  %onnx::Transpose_486 = MatMul(%input.48, %onnx::MatMul_468)\n",
      "  %onnx::Reshape_487 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_486)\n",
      "  %onnx::MatMul_495 = Reshape(%onnx::Reshape_487, %onnx::Reshape_1499)\n",
      "  %onnx::Add_497 = MatMul(%onnx::MatMul_495, %onnx::MatMul_1500)\n",
      "  %input.52 = Add(%bert.encoder.layer.2.attention.output.dense.bias, %onnx::Add_497)\n",
      "  %input.56 = Add(%input.52, %onnx::MatMul_438)\n",
      "  %onnx::Sub_500 = ReduceMean[axes = [-1]](%input.56)\n",
      "  %onnx::Pow_501 = Sub(%input.56, %onnx::Sub_500)\n",
      "  %onnx::Pow_502 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_503 = Pow(%onnx::Pow_501, %onnx::Pow_502)\n",
      "  %onnx::Add_504 = ReduceMean[axes = [-1]](%onnx::ReduceMean_503)\n",
      "  %onnx::Add_505 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_506 = Add(%onnx::Add_504, %onnx::Add_505)\n",
      "  %onnx::Div_507 = Sqrt(%onnx::Sqrt_506)\n",
      "  %onnx::Mul_508 = Div(%onnx::Pow_501, %onnx::Div_507)\n",
      "  %onnx::Add_509 = Mul(%onnx::Mul_508, %bert.encoder.layer.2.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_510 = Add(%onnx::Add_509, %bert.encoder.layer.2.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_512 = MatMul(%onnx::MatMul_510, %onnx::MatMul_1501)\n",
      "  %onnx::Div_513 = Add(%bert.encoder.layer.2.intermediate.dense.bias, %onnx::Add_512)\n",
      "  %onnx::Div_514 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_515 = Div(%onnx::Div_513, %onnx::Div_514)\n",
      "  %onnx::Add_516 = Erf(%onnx::Erf_515)\n",
      "  %onnx::Add_517 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_518 = Add(%onnx::Add_516, %onnx::Add_517)\n",
      "  %onnx::Mul_519 = Mul(%onnx::Div_513, %onnx::Mul_518)\n",
      "  %onnx::Mul_520 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_521 = Mul(%onnx::Mul_519, %onnx::Mul_520)\n",
      "  %onnx::Add_523 = MatMul(%onnx::MatMul_521, %onnx::MatMul_1502)\n",
      "  %input.60 = Add(%bert.encoder.layer.2.output.dense.bias, %onnx::Add_523)\n",
      "  %input.64 = Add(%input.60, %onnx::MatMul_510)\n",
      "  %onnx::Sub_526 = ReduceMean[axes = [-1]](%input.64)\n",
      "  %onnx::Pow_527 = Sub(%input.64, %onnx::Sub_526)\n",
      "  %onnx::Pow_528 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_529 = Pow(%onnx::Pow_527, %onnx::Pow_528)\n",
      "  %onnx::Add_530 = ReduceMean[axes = [-1]](%onnx::ReduceMean_529)\n",
      "  %onnx::Add_531 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_532 = Add(%onnx::Add_530, %onnx::Add_531)\n",
      "  %onnx::Div_533 = Sqrt(%onnx::Sqrt_532)\n",
      "  %onnx::Mul_534 = Div(%onnx::Pow_527, %onnx::Div_533)\n",
      "  %onnx::Add_535 = Mul(%onnx::Mul_534, %bert.encoder.layer.2.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_536 = Add(%onnx::Add_535, %bert.encoder.layer.2.output.LayerNorm.bias)\n",
      "  %onnx::Add_538 = MatMul(%onnx::MatMul_536, %onnx::MatMul_1503)\n",
      "  %mixed_query_layer.11 = Add(%bert.encoder.layer.3.attention.self.query.bias, %onnx::Add_538)\n",
      "  %onnx::Add_541 = MatMul(%onnx::MatMul_536, %onnx::MatMul_1504)\n",
      "  %onnx::Reshape_542 = Add(%bert.encoder.layer.3.attention.self.key.bias, %onnx::Add_541)\n",
      "  %onnx::Transpose_552 = Reshape(%onnx::Reshape_542, %onnx::Reshape_1509)\n",
      "  %onnx::Add_554 = MatMul(%onnx::MatMul_536, %onnx::MatMul_1510)\n",
      "  %onnx::Reshape_555 = Add(%bert.encoder.layer.3.attention.self.value.bias, %onnx::Add_554)\n",
      "  %onnx::Transpose_565 = Reshape(%onnx::Reshape_555, %onnx::Reshape_1515)\n",
      "  %onnx::MatMul_566 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_565)\n",
      "  %onnx::Transpose_576 = Reshape(%mixed_query_layer.11, %onnx::Reshape_1520)\n",
      "  %onnx::MatMul_577 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_576)\n",
      "  %onnx::MatMul_578 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_552)\n",
      "  %onnx::Div_579 = MatMul(%onnx::MatMul_577, %onnx::MatMul_578)\n",
      "  %onnx::Div_580 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_581 = Div(%onnx::Div_579, %onnx::Div_580)\n",
      "  %attention_scores.11 = Add(%onnx::Add_581, %onnx::Add_225)\n",
      "  %input.68 = Softmax[axis = 3](%attention_scores.11)\n",
      "  %onnx::Transpose_584 = MatMul(%input.68, %onnx::MatMul_566)\n",
      "  %onnx::Reshape_585 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_584)\n",
      "  %onnx::MatMul_593 = Reshape(%onnx::Reshape_585, %onnx::Reshape_1524)\n",
      "  %onnx::Add_595 = MatMul(%onnx::MatMul_593, %onnx::MatMul_1525)\n",
      "  %input.72 = Add(%bert.encoder.layer.3.attention.output.dense.bias, %onnx::Add_595)\n",
      "  %input.76 = Add(%input.72, %onnx::MatMul_536)\n",
      "  %onnx::Sub_598 = ReduceMean[axes = [-1]](%input.76)\n",
      "  %onnx::Pow_599 = Sub(%input.76, %onnx::Sub_598)\n",
      "  %onnx::Pow_600 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_601 = Pow(%onnx::Pow_599, %onnx::Pow_600)\n",
      "  %onnx::Add_602 = ReduceMean[axes = [-1]](%onnx::ReduceMean_601)\n",
      "  %onnx::Add_603 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_604 = Add(%onnx::Add_602, %onnx::Add_603)\n",
      "  %onnx::Div_605 = Sqrt(%onnx::Sqrt_604)\n",
      "  %onnx::Mul_606 = Div(%onnx::Pow_599, %onnx::Div_605)\n",
      "  %onnx::Add_607 = Mul(%onnx::Mul_606, %bert.encoder.layer.3.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_608 = Add(%onnx::Add_607, %bert.encoder.layer.3.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_610 = MatMul(%onnx::MatMul_608, %onnx::MatMul_1526)\n",
      "  %onnx::Div_611 = Add(%bert.encoder.layer.3.intermediate.dense.bias, %onnx::Add_610)\n",
      "  %onnx::Div_612 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_613 = Div(%onnx::Div_611, %onnx::Div_612)\n",
      "  %onnx::Add_614 = Erf(%onnx::Erf_613)\n",
      "  %onnx::Add_615 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_616 = Add(%onnx::Add_614, %onnx::Add_615)\n",
      "  %onnx::Mul_617 = Mul(%onnx::Div_611, %onnx::Mul_616)\n",
      "  %onnx::Mul_618 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_619 = Mul(%onnx::Mul_617, %onnx::Mul_618)\n",
      "  %onnx::Add_621 = MatMul(%onnx::MatMul_619, %onnx::MatMul_1527)\n",
      "  %input.80 = Add(%bert.encoder.layer.3.output.dense.bias, %onnx::Add_621)\n",
      "  %input.84 = Add(%input.80, %onnx::MatMul_608)\n",
      "  %onnx::Sub_624 = ReduceMean[axes = [-1]](%input.84)\n",
      "  %onnx::Pow_625 = Sub(%input.84, %onnx::Sub_624)\n",
      "  %onnx::Pow_626 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_627 = Pow(%onnx::Pow_625, %onnx::Pow_626)\n",
      "  %onnx::Add_628 = ReduceMean[axes = [-1]](%onnx::ReduceMean_627)\n",
      "  %onnx::Add_629 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_630 = Add(%onnx::Add_628, %onnx::Add_629)\n",
      "  %onnx::Div_631 = Sqrt(%onnx::Sqrt_630)\n",
      "  %onnx::Mul_632 = Div(%onnx::Pow_625, %onnx::Div_631)\n",
      "  %onnx::Add_633 = Mul(%onnx::Mul_632, %bert.encoder.layer.3.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_634 = Add(%onnx::Add_633, %bert.encoder.layer.3.output.LayerNorm.bias)\n",
      "  %onnx::Add_636 = MatMul(%onnx::MatMul_634, %onnx::MatMul_1528)\n",
      "  %mixed_query_layer.15 = Add(%bert.encoder.layer.4.attention.self.query.bias, %onnx::Add_636)\n",
      "  %onnx::Add_639 = MatMul(%onnx::MatMul_634, %onnx::MatMul_1529)\n",
      "  %onnx::Reshape_640 = Add(%bert.encoder.layer.4.attention.self.key.bias, %onnx::Add_639)\n",
      "  %onnx::Transpose_650 = Reshape(%onnx::Reshape_640, %onnx::Reshape_1534)\n",
      "  %onnx::Add_652 = MatMul(%onnx::MatMul_634, %onnx::MatMul_1535)\n",
      "  %onnx::Reshape_653 = Add(%bert.encoder.layer.4.attention.self.value.bias, %onnx::Add_652)\n",
      "  %onnx::Transpose_663 = Reshape(%onnx::Reshape_653, %onnx::Reshape_1540)\n",
      "  %onnx::MatMul_664 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_663)\n",
      "  %onnx::Transpose_674 = Reshape(%mixed_query_layer.15, %onnx::Reshape_1545)\n",
      "  %onnx::MatMul_675 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_674)\n",
      "  %onnx::MatMul_676 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_650)\n",
      "  %onnx::Div_677 = MatMul(%onnx::MatMul_675, %onnx::MatMul_676)\n",
      "  %onnx::Div_678 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_679 = Div(%onnx::Div_677, %onnx::Div_678)\n",
      "  %attention_scores.15 = Add(%onnx::Add_679, %onnx::Add_225)\n",
      "  %input.88 = Softmax[axis = 3](%attention_scores.15)\n",
      "  %onnx::Transpose_682 = MatMul(%input.88, %onnx::MatMul_664)\n",
      "  %onnx::Reshape_683 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_682)\n",
      "  %onnx::MatMul_691 = Reshape(%onnx::Reshape_683, %onnx::Reshape_1549)\n",
      "  %onnx::Add_693 = MatMul(%onnx::MatMul_691, %onnx::MatMul_1550)\n",
      "  %input.92 = Add(%bert.encoder.layer.4.attention.output.dense.bias, %onnx::Add_693)\n",
      "  %input.96 = Add(%input.92, %onnx::MatMul_634)\n",
      "  %onnx::Sub_696 = ReduceMean[axes = [-1]](%input.96)\n",
      "  %onnx::Pow_697 = Sub(%input.96, %onnx::Sub_696)\n",
      "  %onnx::Pow_698 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_699 = Pow(%onnx::Pow_697, %onnx::Pow_698)\n",
      "  %onnx::Add_700 = ReduceMean[axes = [-1]](%onnx::ReduceMean_699)\n",
      "  %onnx::Add_701 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_702 = Add(%onnx::Add_700, %onnx::Add_701)\n",
      "  %onnx::Div_703 = Sqrt(%onnx::Sqrt_702)\n",
      "  %onnx::Mul_704 = Div(%onnx::Pow_697, %onnx::Div_703)\n",
      "  %onnx::Add_705 = Mul(%onnx::Mul_704, %bert.encoder.layer.4.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_706 = Add(%onnx::Add_705, %bert.encoder.layer.4.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_708 = MatMul(%onnx::MatMul_706, %onnx::MatMul_1551)\n",
      "  %onnx::Div_709 = Add(%bert.encoder.layer.4.intermediate.dense.bias, %onnx::Add_708)\n",
      "  %onnx::Div_710 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_711 = Div(%onnx::Div_709, %onnx::Div_710)\n",
      "  %onnx::Add_712 = Erf(%onnx::Erf_711)\n",
      "  %onnx::Add_713 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_714 = Add(%onnx::Add_712, %onnx::Add_713)\n",
      "  %onnx::Mul_715 = Mul(%onnx::Div_709, %onnx::Mul_714)\n",
      "  %onnx::Mul_716 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_717 = Mul(%onnx::Mul_715, %onnx::Mul_716)\n",
      "  %onnx::Add_719 = MatMul(%onnx::MatMul_717, %onnx::MatMul_1552)\n",
      "  %input.100 = Add(%bert.encoder.layer.4.output.dense.bias, %onnx::Add_719)\n",
      "  %input.104 = Add(%input.100, %onnx::MatMul_706)\n",
      "  %onnx::Sub_722 = ReduceMean[axes = [-1]](%input.104)\n",
      "  %onnx::Pow_723 = Sub(%input.104, %onnx::Sub_722)\n",
      "  %onnx::Pow_724 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_725 = Pow(%onnx::Pow_723, %onnx::Pow_724)\n",
      "  %onnx::Add_726 = ReduceMean[axes = [-1]](%onnx::ReduceMean_725)\n",
      "  %onnx::Add_727 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_728 = Add(%onnx::Add_726, %onnx::Add_727)\n",
      "  %onnx::Div_729 = Sqrt(%onnx::Sqrt_728)\n",
      "  %onnx::Mul_730 = Div(%onnx::Pow_723, %onnx::Div_729)\n",
      "  %onnx::Add_731 = Mul(%onnx::Mul_730, %bert.encoder.layer.4.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_732 = Add(%onnx::Add_731, %bert.encoder.layer.4.output.LayerNorm.bias)\n",
      "  %onnx::Add_734 = MatMul(%onnx::MatMul_732, %onnx::MatMul_1553)\n",
      "  %mixed_query_layer.19 = Add(%bert.encoder.layer.5.attention.self.query.bias, %onnx::Add_734)\n",
      "  %onnx::Add_737 = MatMul(%onnx::MatMul_732, %onnx::MatMul_1554)\n",
      "  %onnx::Reshape_738 = Add(%bert.encoder.layer.5.attention.self.key.bias, %onnx::Add_737)\n",
      "  %onnx::Transpose_748 = Reshape(%onnx::Reshape_738, %onnx::Reshape_1559)\n",
      "  %onnx::Add_750 = MatMul(%onnx::MatMul_732, %onnx::MatMul_1560)\n",
      "  %onnx::Reshape_751 = Add(%bert.encoder.layer.5.attention.self.value.bias, %onnx::Add_750)\n",
      "  %onnx::Transpose_761 = Reshape(%onnx::Reshape_751, %onnx::Reshape_1565)\n",
      "  %onnx::MatMul_762 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_761)\n",
      "  %onnx::Transpose_772 = Reshape(%mixed_query_layer.19, %onnx::Reshape_1570)\n",
      "  %onnx::MatMul_773 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_772)\n",
      "  %onnx::MatMul_774 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_748)\n",
      "  %onnx::Div_775 = MatMul(%onnx::MatMul_773, %onnx::MatMul_774)\n",
      "  %onnx::Div_776 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_777 = Div(%onnx::Div_775, %onnx::Div_776)\n",
      "  %attention_scores.19 = Add(%onnx::Add_777, %onnx::Add_225)\n",
      "  %input.108 = Softmax[axis = 3](%attention_scores.19)\n",
      "  %onnx::Transpose_780 = MatMul(%input.108, %onnx::MatMul_762)\n",
      "  %onnx::Reshape_781 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_780)\n",
      "  %onnx::MatMul_789 = Reshape(%onnx::Reshape_781, %onnx::Reshape_1574)\n",
      "  %onnx::Add_791 = MatMul(%onnx::MatMul_789, %onnx::MatMul_1575)\n",
      "  %input.112 = Add(%bert.encoder.layer.5.attention.output.dense.bias, %onnx::Add_791)\n",
      "  %input.116 = Add(%input.112, %onnx::MatMul_732)\n",
      "  %onnx::Sub_794 = ReduceMean[axes = [-1]](%input.116)\n",
      "  %onnx::Pow_795 = Sub(%input.116, %onnx::Sub_794)\n",
      "  %onnx::Pow_796 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_797 = Pow(%onnx::Pow_795, %onnx::Pow_796)\n",
      "  %onnx::Add_798 = ReduceMean[axes = [-1]](%onnx::ReduceMean_797)\n",
      "  %onnx::Add_799 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_800 = Add(%onnx::Add_798, %onnx::Add_799)\n",
      "  %onnx::Div_801 = Sqrt(%onnx::Sqrt_800)\n",
      "  %onnx::Mul_802 = Div(%onnx::Pow_795, %onnx::Div_801)\n",
      "  %onnx::Add_803 = Mul(%onnx::Mul_802, %bert.encoder.layer.5.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_804 = Add(%onnx::Add_803, %bert.encoder.layer.5.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_806 = MatMul(%onnx::MatMul_804, %onnx::MatMul_1576)\n",
      "  %onnx::Div_807 = Add(%bert.encoder.layer.5.intermediate.dense.bias, %onnx::Add_806)\n",
      "  %onnx::Div_808 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_809 = Div(%onnx::Div_807, %onnx::Div_808)\n",
      "  %onnx::Add_810 = Erf(%onnx::Erf_809)\n",
      "  %onnx::Add_811 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_812 = Add(%onnx::Add_810, %onnx::Add_811)\n",
      "  %onnx::Mul_813 = Mul(%onnx::Div_807, %onnx::Mul_812)\n",
      "  %onnx::Mul_814 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_815 = Mul(%onnx::Mul_813, %onnx::Mul_814)\n",
      "  %onnx::Add_817 = MatMul(%onnx::MatMul_815, %onnx::MatMul_1577)\n",
      "  %input.120 = Add(%bert.encoder.layer.5.output.dense.bias, %onnx::Add_817)\n",
      "  %input.124 = Add(%input.120, %onnx::MatMul_804)\n",
      "  %onnx::Sub_820 = ReduceMean[axes = [-1]](%input.124)\n",
      "  %onnx::Pow_821 = Sub(%input.124, %onnx::Sub_820)\n",
      "  %onnx::Pow_822 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_823 = Pow(%onnx::Pow_821, %onnx::Pow_822)\n",
      "  %onnx::Add_824 = ReduceMean[axes = [-1]](%onnx::ReduceMean_823)\n",
      "  %onnx::Add_825 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_826 = Add(%onnx::Add_824, %onnx::Add_825)\n",
      "  %onnx::Div_827 = Sqrt(%onnx::Sqrt_826)\n",
      "  %onnx::Mul_828 = Div(%onnx::Pow_821, %onnx::Div_827)\n",
      "  %onnx::Add_829 = Mul(%onnx::Mul_828, %bert.encoder.layer.5.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_830 = Add(%onnx::Add_829, %bert.encoder.layer.5.output.LayerNorm.bias)\n",
      "  %onnx::Add_832 = MatMul(%onnx::MatMul_830, %onnx::MatMul_1578)\n",
      "  %mixed_query_layer.23 = Add(%bert.encoder.layer.6.attention.self.query.bias, %onnx::Add_832)\n",
      "  %onnx::Add_835 = MatMul(%onnx::MatMul_830, %onnx::MatMul_1579)\n",
      "  %onnx::Reshape_836 = Add(%bert.encoder.layer.6.attention.self.key.bias, %onnx::Add_835)\n",
      "  %onnx::Transpose_846 = Reshape(%onnx::Reshape_836, %onnx::Reshape_1584)\n",
      "  %onnx::Add_848 = MatMul(%onnx::MatMul_830, %onnx::MatMul_1585)\n",
      "  %onnx::Reshape_849 = Add(%bert.encoder.layer.6.attention.self.value.bias, %onnx::Add_848)\n",
      "  %onnx::Transpose_859 = Reshape(%onnx::Reshape_849, %onnx::Reshape_1590)\n",
      "  %onnx::MatMul_860 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_859)\n",
      "  %onnx::Transpose_870 = Reshape(%mixed_query_layer.23, %onnx::Reshape_1595)\n",
      "  %onnx::MatMul_871 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_870)\n",
      "  %onnx::MatMul_872 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_846)\n",
      "  %onnx::Div_873 = MatMul(%onnx::MatMul_871, %onnx::MatMul_872)\n",
      "  %onnx::Div_874 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_875 = Div(%onnx::Div_873, %onnx::Div_874)\n",
      "  %attention_scores.23 = Add(%onnx::Add_875, %onnx::Add_225)\n",
      "  %input.128 = Softmax[axis = 3](%attention_scores.23)\n",
      "  %onnx::Transpose_878 = MatMul(%input.128, %onnx::MatMul_860)\n",
      "  %onnx::Reshape_879 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_878)\n",
      "  %onnx::MatMul_887 = Reshape(%onnx::Reshape_879, %onnx::Reshape_1599)\n",
      "  %onnx::Add_889 = MatMul(%onnx::MatMul_887, %onnx::MatMul_1600)\n",
      "  %input.132 = Add(%bert.encoder.layer.6.attention.output.dense.bias, %onnx::Add_889)\n",
      "  %input.136 = Add(%input.132, %onnx::MatMul_830)\n",
      "  %onnx::Sub_892 = ReduceMean[axes = [-1]](%input.136)\n",
      "  %onnx::Pow_893 = Sub(%input.136, %onnx::Sub_892)\n",
      "  %onnx::Pow_894 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_895 = Pow(%onnx::Pow_893, %onnx::Pow_894)\n",
      "  %onnx::Add_896 = ReduceMean[axes = [-1]](%onnx::ReduceMean_895)\n",
      "  %onnx::Add_897 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_898 = Add(%onnx::Add_896, %onnx::Add_897)\n",
      "  %onnx::Div_899 = Sqrt(%onnx::Sqrt_898)\n",
      "  %onnx::Mul_900 = Div(%onnx::Pow_893, %onnx::Div_899)\n",
      "  %onnx::Add_901 = Mul(%onnx::Mul_900, %bert.encoder.layer.6.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_902 = Add(%onnx::Add_901, %bert.encoder.layer.6.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_904 = MatMul(%onnx::MatMul_902, %onnx::MatMul_1601)\n",
      "  %onnx::Div_905 = Add(%bert.encoder.layer.6.intermediate.dense.bias, %onnx::Add_904)\n",
      "  %onnx::Div_906 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_907 = Div(%onnx::Div_905, %onnx::Div_906)\n",
      "  %onnx::Add_908 = Erf(%onnx::Erf_907)\n",
      "  %onnx::Add_909 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_910 = Add(%onnx::Add_908, %onnx::Add_909)\n",
      "  %onnx::Mul_911 = Mul(%onnx::Div_905, %onnx::Mul_910)\n",
      "  %onnx::Mul_912 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_913 = Mul(%onnx::Mul_911, %onnx::Mul_912)\n",
      "  %onnx::Add_915 = MatMul(%onnx::MatMul_913, %onnx::MatMul_1602)\n",
      "  %input.140 = Add(%bert.encoder.layer.6.output.dense.bias, %onnx::Add_915)\n",
      "  %input.144 = Add(%input.140, %onnx::MatMul_902)\n",
      "  %onnx::Sub_918 = ReduceMean[axes = [-1]](%input.144)\n",
      "  %onnx::Pow_919 = Sub(%input.144, %onnx::Sub_918)\n",
      "  %onnx::Pow_920 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_921 = Pow(%onnx::Pow_919, %onnx::Pow_920)\n",
      "  %onnx::Add_922 = ReduceMean[axes = [-1]](%onnx::ReduceMean_921)\n",
      "  %onnx::Add_923 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_924 = Add(%onnx::Add_922, %onnx::Add_923)\n",
      "  %onnx::Div_925 = Sqrt(%onnx::Sqrt_924)\n",
      "  %onnx::Mul_926 = Div(%onnx::Pow_919, %onnx::Div_925)\n",
      "  %onnx::Add_927 = Mul(%onnx::Mul_926, %bert.encoder.layer.6.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_928 = Add(%onnx::Add_927, %bert.encoder.layer.6.output.LayerNorm.bias)\n",
      "  %onnx::Add_930 = MatMul(%onnx::MatMul_928, %onnx::MatMul_1603)\n",
      "  %mixed_query_layer.27 = Add(%bert.encoder.layer.7.attention.self.query.bias, %onnx::Add_930)\n",
      "  %onnx::Add_933 = MatMul(%onnx::MatMul_928, %onnx::MatMul_1604)\n",
      "  %onnx::Reshape_934 = Add(%bert.encoder.layer.7.attention.self.key.bias, %onnx::Add_933)\n",
      "  %onnx::Transpose_944 = Reshape(%onnx::Reshape_934, %onnx::Reshape_1609)\n",
      "  %onnx::Add_946 = MatMul(%onnx::MatMul_928, %onnx::MatMul_1610)\n",
      "  %onnx::Reshape_947 = Add(%bert.encoder.layer.7.attention.self.value.bias, %onnx::Add_946)\n",
      "  %onnx::Transpose_957 = Reshape(%onnx::Reshape_947, %onnx::Reshape_1615)\n",
      "  %onnx::MatMul_958 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_957)\n",
      "  %onnx::Transpose_968 = Reshape(%mixed_query_layer.27, %onnx::Reshape_1620)\n",
      "  %onnx::MatMul_969 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_968)\n",
      "  %onnx::MatMul_970 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_944)\n",
      "  %onnx::Div_971 = MatMul(%onnx::MatMul_969, %onnx::MatMul_970)\n",
      "  %onnx::Div_972 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_973 = Div(%onnx::Div_971, %onnx::Div_972)\n",
      "  %attention_scores.27 = Add(%onnx::Add_973, %onnx::Add_225)\n",
      "  %input.148 = Softmax[axis = 3](%attention_scores.27)\n",
      "  %onnx::Transpose_976 = MatMul(%input.148, %onnx::MatMul_958)\n",
      "  %onnx::Reshape_977 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_976)\n",
      "  %onnx::MatMul_985 = Reshape(%onnx::Reshape_977, %onnx::Reshape_1624)\n",
      "  %onnx::Add_987 = MatMul(%onnx::MatMul_985, %onnx::MatMul_1625)\n",
      "  %input.152 = Add(%bert.encoder.layer.7.attention.output.dense.bias, %onnx::Add_987)\n",
      "  %input.156 = Add(%input.152, %onnx::MatMul_928)\n",
      "  %onnx::Sub_990 = ReduceMean[axes = [-1]](%input.156)\n",
      "  %onnx::Pow_991 = Sub(%input.156, %onnx::Sub_990)\n",
      "  %onnx::Pow_992 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_993 = Pow(%onnx::Pow_991, %onnx::Pow_992)\n",
      "  %onnx::Add_994 = ReduceMean[axes = [-1]](%onnx::ReduceMean_993)\n",
      "  %onnx::Add_995 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_996 = Add(%onnx::Add_994, %onnx::Add_995)\n",
      "  %onnx::Div_997 = Sqrt(%onnx::Sqrt_996)\n",
      "  %onnx::Mul_998 = Div(%onnx::Pow_991, %onnx::Div_997)\n",
      "  %onnx::Add_999 = Mul(%onnx::Mul_998, %bert.encoder.layer.7.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1000 = Add(%onnx::Add_999, %bert.encoder.layer.7.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1002 = MatMul(%onnx::MatMul_1000, %onnx::MatMul_1626)\n",
      "  %onnx::Div_1003 = Add(%bert.encoder.layer.7.intermediate.dense.bias, %onnx::Add_1002)\n",
      "  %onnx::Div_1004 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1005 = Div(%onnx::Div_1003, %onnx::Div_1004)\n",
      "  %onnx::Add_1006 = Erf(%onnx::Erf_1005)\n",
      "  %onnx::Add_1007 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1008 = Add(%onnx::Add_1006, %onnx::Add_1007)\n",
      "  %onnx::Mul_1009 = Mul(%onnx::Div_1003, %onnx::Mul_1008)\n",
      "  %onnx::Mul_1010 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1011 = Mul(%onnx::Mul_1009, %onnx::Mul_1010)\n",
      "  %onnx::Add_1013 = MatMul(%onnx::MatMul_1011, %onnx::MatMul_1627)\n",
      "  %input.160 = Add(%bert.encoder.layer.7.output.dense.bias, %onnx::Add_1013)\n",
      "  %input.164 = Add(%input.160, %onnx::MatMul_1000)\n",
      "  %onnx::Sub_1016 = ReduceMean[axes = [-1]](%input.164)\n",
      "  %onnx::Pow_1017 = Sub(%input.164, %onnx::Sub_1016)\n",
      "  %onnx::Pow_1018 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1019 = Pow(%onnx::Pow_1017, %onnx::Pow_1018)\n",
      "  %onnx::Add_1020 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1019)\n",
      "  %onnx::Add_1021 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1022 = Add(%onnx::Add_1020, %onnx::Add_1021)\n",
      "  %onnx::Div_1023 = Sqrt(%onnx::Sqrt_1022)\n",
      "  %onnx::Mul_1024 = Div(%onnx::Pow_1017, %onnx::Div_1023)\n",
      "  %onnx::Add_1025 = Mul(%onnx::Mul_1024, %bert.encoder.layer.7.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1026 = Add(%onnx::Add_1025, %bert.encoder.layer.7.output.LayerNorm.bias)\n",
      "  %onnx::Add_1028 = MatMul(%onnx::MatMul_1026, %onnx::MatMul_1628)\n",
      "  %mixed_query_layer.31 = Add(%bert.encoder.layer.8.attention.self.query.bias, %onnx::Add_1028)\n",
      "  %onnx::Add_1031 = MatMul(%onnx::MatMul_1026, %onnx::MatMul_1629)\n",
      "  %onnx::Reshape_1032 = Add(%bert.encoder.layer.8.attention.self.key.bias, %onnx::Add_1031)\n",
      "  %onnx::Transpose_1042 = Reshape(%onnx::Reshape_1032, %onnx::Reshape_1634)\n",
      "  %onnx::Add_1044 = MatMul(%onnx::MatMul_1026, %onnx::MatMul_1635)\n",
      "  %onnx::Reshape_1045 = Add(%bert.encoder.layer.8.attention.self.value.bias, %onnx::Add_1044)\n",
      "  %onnx::Transpose_1055 = Reshape(%onnx::Reshape_1045, %onnx::Reshape_1640)\n",
      "  %onnx::MatMul_1056 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1055)\n",
      "  %onnx::Transpose_1066 = Reshape(%mixed_query_layer.31, %onnx::Reshape_1645)\n",
      "  %onnx::MatMul_1067 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1066)\n",
      "  %onnx::MatMul_1068 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1042)\n",
      "  %onnx::Div_1069 = MatMul(%onnx::MatMul_1067, %onnx::MatMul_1068)\n",
      "  %onnx::Div_1070 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1071 = Div(%onnx::Div_1069, %onnx::Div_1070)\n",
      "  %attention_scores.31 = Add(%onnx::Add_1071, %onnx::Add_225)\n",
      "  %input.168 = Softmax[axis = 3](%attention_scores.31)\n",
      "  %onnx::Transpose_1074 = MatMul(%input.168, %onnx::MatMul_1056)\n",
      "  %onnx::Reshape_1075 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1074)\n",
      "  %onnx::MatMul_1083 = Reshape(%onnx::Reshape_1075, %onnx::Reshape_1649)\n",
      "  %onnx::Add_1085 = MatMul(%onnx::MatMul_1083, %onnx::MatMul_1650)\n",
      "  %input.172 = Add(%bert.encoder.layer.8.attention.output.dense.bias, %onnx::Add_1085)\n",
      "  %input.176 = Add(%input.172, %onnx::MatMul_1026)\n",
      "  %onnx::Sub_1088 = ReduceMean[axes = [-1]](%input.176)\n",
      "  %onnx::Pow_1089 = Sub(%input.176, %onnx::Sub_1088)\n",
      "  %onnx::Pow_1090 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1091 = Pow(%onnx::Pow_1089, %onnx::Pow_1090)\n",
      "  %onnx::Add_1092 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1091)\n",
      "  %onnx::Add_1093 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1094 = Add(%onnx::Add_1092, %onnx::Add_1093)\n",
      "  %onnx::Div_1095 = Sqrt(%onnx::Sqrt_1094)\n",
      "  %onnx::Mul_1096 = Div(%onnx::Pow_1089, %onnx::Div_1095)\n",
      "  %onnx::Add_1097 = Mul(%onnx::Mul_1096, %bert.encoder.layer.8.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1098 = Add(%onnx::Add_1097, %bert.encoder.layer.8.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1100 = MatMul(%onnx::MatMul_1098, %onnx::MatMul_1651)\n",
      "  %onnx::Div_1101 = Add(%bert.encoder.layer.8.intermediate.dense.bias, %onnx::Add_1100)\n",
      "  %onnx::Div_1102 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1103 = Div(%onnx::Div_1101, %onnx::Div_1102)\n",
      "  %onnx::Add_1104 = Erf(%onnx::Erf_1103)\n",
      "  %onnx::Add_1105 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1106 = Add(%onnx::Add_1104, %onnx::Add_1105)\n",
      "  %onnx::Mul_1107 = Mul(%onnx::Div_1101, %onnx::Mul_1106)\n",
      "  %onnx::Mul_1108 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1109 = Mul(%onnx::Mul_1107, %onnx::Mul_1108)\n",
      "  %onnx::Add_1111 = MatMul(%onnx::MatMul_1109, %onnx::MatMul_1652)\n",
      "  %input.180 = Add(%bert.encoder.layer.8.output.dense.bias, %onnx::Add_1111)\n",
      "  %input.184 = Add(%input.180, %onnx::MatMul_1098)\n",
      "  %onnx::Sub_1114 = ReduceMean[axes = [-1]](%input.184)\n",
      "  %onnx::Pow_1115 = Sub(%input.184, %onnx::Sub_1114)\n",
      "  %onnx::Pow_1116 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1117 = Pow(%onnx::Pow_1115, %onnx::Pow_1116)\n",
      "  %onnx::Add_1118 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1117)\n",
      "  %onnx::Add_1119 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1120 = Add(%onnx::Add_1118, %onnx::Add_1119)\n",
      "  %onnx::Div_1121 = Sqrt(%onnx::Sqrt_1120)\n",
      "  %onnx::Mul_1122 = Div(%onnx::Pow_1115, %onnx::Div_1121)\n",
      "  %onnx::Add_1123 = Mul(%onnx::Mul_1122, %bert.encoder.layer.8.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1124 = Add(%onnx::Add_1123, %bert.encoder.layer.8.output.LayerNorm.bias)\n",
      "  %onnx::Add_1126 = MatMul(%onnx::MatMul_1124, %onnx::MatMul_1653)\n",
      "  %mixed_query_layer.35 = Add(%bert.encoder.layer.9.attention.self.query.bias, %onnx::Add_1126)\n",
      "  %onnx::Add_1129 = MatMul(%onnx::MatMul_1124, %onnx::MatMul_1654)\n",
      "  %onnx::Reshape_1130 = Add(%bert.encoder.layer.9.attention.self.key.bias, %onnx::Add_1129)\n",
      "  %onnx::Transpose_1140 = Reshape(%onnx::Reshape_1130, %onnx::Reshape_1659)\n",
      "  %onnx::Add_1142 = MatMul(%onnx::MatMul_1124, %onnx::MatMul_1660)\n",
      "  %onnx::Reshape_1143 = Add(%bert.encoder.layer.9.attention.self.value.bias, %onnx::Add_1142)\n",
      "  %onnx::Transpose_1153 = Reshape(%onnx::Reshape_1143, %onnx::Reshape_1665)\n",
      "  %onnx::MatMul_1154 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1153)\n",
      "  %onnx::Transpose_1164 = Reshape(%mixed_query_layer.35, %onnx::Reshape_1670)\n",
      "  %onnx::MatMul_1165 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1164)\n",
      "  %onnx::MatMul_1166 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1140)\n",
      "  %onnx::Div_1167 = MatMul(%onnx::MatMul_1165, %onnx::MatMul_1166)\n",
      "  %onnx::Div_1168 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1169 = Div(%onnx::Div_1167, %onnx::Div_1168)\n",
      "  %attention_scores.35 = Add(%onnx::Add_1169, %onnx::Add_225)\n",
      "  %input.188 = Softmax[axis = 3](%attention_scores.35)\n",
      "  %onnx::Transpose_1172 = MatMul(%input.188, %onnx::MatMul_1154)\n",
      "  %onnx::Reshape_1173 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1172)\n",
      "  %onnx::MatMul_1181 = Reshape(%onnx::Reshape_1173, %onnx::Reshape_1674)\n",
      "  %onnx::Add_1183 = MatMul(%onnx::MatMul_1181, %onnx::MatMul_1675)\n",
      "  %input.192 = Add(%bert.encoder.layer.9.attention.output.dense.bias, %onnx::Add_1183)\n",
      "  %input.196 = Add(%input.192, %onnx::MatMul_1124)\n",
      "  %onnx::Sub_1186 = ReduceMean[axes = [-1]](%input.196)\n",
      "  %onnx::Pow_1187 = Sub(%input.196, %onnx::Sub_1186)\n",
      "  %onnx::Pow_1188 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1189 = Pow(%onnx::Pow_1187, %onnx::Pow_1188)\n",
      "  %onnx::Add_1190 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1189)\n",
      "  %onnx::Add_1191 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1192 = Add(%onnx::Add_1190, %onnx::Add_1191)\n",
      "  %onnx::Div_1193 = Sqrt(%onnx::Sqrt_1192)\n",
      "  %onnx::Mul_1194 = Div(%onnx::Pow_1187, %onnx::Div_1193)\n",
      "  %onnx::Add_1195 = Mul(%onnx::Mul_1194, %bert.encoder.layer.9.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1196 = Add(%onnx::Add_1195, %bert.encoder.layer.9.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1198 = MatMul(%onnx::MatMul_1196, %onnx::MatMul_1676)\n",
      "  %onnx::Div_1199 = Add(%bert.encoder.layer.9.intermediate.dense.bias, %onnx::Add_1198)\n",
      "  %onnx::Div_1200 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1201 = Div(%onnx::Div_1199, %onnx::Div_1200)\n",
      "  %onnx::Add_1202 = Erf(%onnx::Erf_1201)\n",
      "  %onnx::Add_1203 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1204 = Add(%onnx::Add_1202, %onnx::Add_1203)\n",
      "  %onnx::Mul_1205 = Mul(%onnx::Div_1199, %onnx::Mul_1204)\n",
      "  %onnx::Mul_1206 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1207 = Mul(%onnx::Mul_1205, %onnx::Mul_1206)\n",
      "  %onnx::Add_1209 = MatMul(%onnx::MatMul_1207, %onnx::MatMul_1677)\n",
      "  %input.200 = Add(%bert.encoder.layer.9.output.dense.bias, %onnx::Add_1209)\n",
      "  %input.204 = Add(%input.200, %onnx::MatMul_1196)\n",
      "  %onnx::Sub_1212 = ReduceMean[axes = [-1]](%input.204)\n",
      "  %onnx::Pow_1213 = Sub(%input.204, %onnx::Sub_1212)\n",
      "  %onnx::Pow_1214 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1215 = Pow(%onnx::Pow_1213, %onnx::Pow_1214)\n",
      "  %onnx::Add_1216 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1215)\n",
      "  %onnx::Add_1217 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1218 = Add(%onnx::Add_1216, %onnx::Add_1217)\n",
      "  %onnx::Div_1219 = Sqrt(%onnx::Sqrt_1218)\n",
      "  %onnx::Mul_1220 = Div(%onnx::Pow_1213, %onnx::Div_1219)\n",
      "  %onnx::Add_1221 = Mul(%onnx::Mul_1220, %bert.encoder.layer.9.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1222 = Add(%onnx::Add_1221, %bert.encoder.layer.9.output.LayerNorm.bias)\n",
      "  %onnx::Add_1224 = MatMul(%onnx::MatMul_1222, %onnx::MatMul_1678)\n",
      "  %mixed_query_layer.39 = Add(%bert.encoder.layer.10.attention.self.query.bias, %onnx::Add_1224)\n",
      "  %onnx::Add_1227 = MatMul(%onnx::MatMul_1222, %onnx::MatMul_1679)\n",
      "  %onnx::Reshape_1228 = Add(%bert.encoder.layer.10.attention.self.key.bias, %onnx::Add_1227)\n",
      "  %onnx::Transpose_1238 = Reshape(%onnx::Reshape_1228, %onnx::Reshape_1684)\n",
      "  %onnx::Add_1240 = MatMul(%onnx::MatMul_1222, %onnx::MatMul_1685)\n",
      "  %onnx::Reshape_1241 = Add(%bert.encoder.layer.10.attention.self.value.bias, %onnx::Add_1240)\n",
      "  %onnx::Transpose_1251 = Reshape(%onnx::Reshape_1241, %onnx::Reshape_1690)\n",
      "  %onnx::MatMul_1252 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1251)\n",
      "  %onnx::Transpose_1262 = Reshape(%mixed_query_layer.39, %onnx::Reshape_1695)\n",
      "  %onnx::MatMul_1263 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1262)\n",
      "  %onnx::MatMul_1264 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1238)\n",
      "  %onnx::Div_1265 = MatMul(%onnx::MatMul_1263, %onnx::MatMul_1264)\n",
      "  %onnx::Div_1266 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1267 = Div(%onnx::Div_1265, %onnx::Div_1266)\n",
      "  %attention_scores.39 = Add(%onnx::Add_1267, %onnx::Add_225)\n",
      "  %input.208 = Softmax[axis = 3](%attention_scores.39)\n",
      "  %onnx::Transpose_1270 = MatMul(%input.208, %onnx::MatMul_1252)\n",
      "  %onnx::Reshape_1271 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1270)\n",
      "  %onnx::MatMul_1279 = Reshape(%onnx::Reshape_1271, %onnx::Reshape_1699)\n",
      "  %onnx::Add_1281 = MatMul(%onnx::MatMul_1279, %onnx::MatMul_1700)\n",
      "  %input.212 = Add(%bert.encoder.layer.10.attention.output.dense.bias, %onnx::Add_1281)\n",
      "  %input.216 = Add(%input.212, %onnx::MatMul_1222)\n",
      "  %onnx::Sub_1284 = ReduceMean[axes = [-1]](%input.216)\n",
      "  %onnx::Pow_1285 = Sub(%input.216, %onnx::Sub_1284)\n",
      "  %onnx::Pow_1286 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1287 = Pow(%onnx::Pow_1285, %onnx::Pow_1286)\n",
      "  %onnx::Add_1288 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1287)\n",
      "  %onnx::Add_1289 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1290 = Add(%onnx::Add_1288, %onnx::Add_1289)\n",
      "  %onnx::Div_1291 = Sqrt(%onnx::Sqrt_1290)\n",
      "  %onnx::Mul_1292 = Div(%onnx::Pow_1285, %onnx::Div_1291)\n",
      "  %onnx::Add_1293 = Mul(%onnx::Mul_1292, %bert.encoder.layer.10.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1294 = Add(%onnx::Add_1293, %bert.encoder.layer.10.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1296 = MatMul(%onnx::MatMul_1294, %onnx::MatMul_1701)\n",
      "  %onnx::Div_1297 = Add(%bert.encoder.layer.10.intermediate.dense.bias, %onnx::Add_1296)\n",
      "  %onnx::Div_1298 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1299 = Div(%onnx::Div_1297, %onnx::Div_1298)\n",
      "  %onnx::Add_1300 = Erf(%onnx::Erf_1299)\n",
      "  %onnx::Add_1301 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1302 = Add(%onnx::Add_1300, %onnx::Add_1301)\n",
      "  %onnx::Mul_1303 = Mul(%onnx::Div_1297, %onnx::Mul_1302)\n",
      "  %onnx::Mul_1304 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1305 = Mul(%onnx::Mul_1303, %onnx::Mul_1304)\n",
      "  %onnx::Add_1307 = MatMul(%onnx::MatMul_1305, %onnx::MatMul_1702)\n",
      "  %input.220 = Add(%bert.encoder.layer.10.output.dense.bias, %onnx::Add_1307)\n",
      "  %input.224 = Add(%input.220, %onnx::MatMul_1294)\n",
      "  %onnx::Sub_1310 = ReduceMean[axes = [-1]](%input.224)\n",
      "  %onnx::Pow_1311 = Sub(%input.224, %onnx::Sub_1310)\n",
      "  %onnx::Pow_1312 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1313 = Pow(%onnx::Pow_1311, %onnx::Pow_1312)\n",
      "  %onnx::Add_1314 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1313)\n",
      "  %onnx::Add_1315 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1316 = Add(%onnx::Add_1314, %onnx::Add_1315)\n",
      "  %onnx::Div_1317 = Sqrt(%onnx::Sqrt_1316)\n",
      "  %onnx::Mul_1318 = Div(%onnx::Pow_1311, %onnx::Div_1317)\n",
      "  %onnx::Add_1319 = Mul(%onnx::Mul_1318, %bert.encoder.layer.10.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1320 = Add(%onnx::Add_1319, %bert.encoder.layer.10.output.LayerNorm.bias)\n",
      "  %onnx::Add_1322 = MatMul(%onnx::MatMul_1320, %onnx::MatMul_1703)\n",
      "  %mixed_query_layer.43 = Add(%bert.encoder.layer.11.attention.self.query.bias, %onnx::Add_1322)\n",
      "  %onnx::Add_1325 = MatMul(%onnx::MatMul_1320, %onnx::MatMul_1704)\n",
      "  %onnx::Reshape_1326 = Add(%bert.encoder.layer.11.attention.self.key.bias, %onnx::Add_1325)\n",
      "  %onnx::Transpose_1336 = Reshape(%onnx::Reshape_1326, %onnx::Reshape_1709)\n",
      "  %onnx::Add_1338 = MatMul(%onnx::MatMul_1320, %onnx::MatMul_1710)\n",
      "  %onnx::Reshape_1339 = Add(%bert.encoder.layer.11.attention.self.value.bias, %onnx::Add_1338)\n",
      "  %onnx::Transpose_1349 = Reshape(%onnx::Reshape_1339, %onnx::Reshape_1715)\n",
      "  %onnx::MatMul_1350 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1349)\n",
      "  %onnx::Transpose_1360 = Reshape(%mixed_query_layer.43, %onnx::Reshape_1720)\n",
      "  %onnx::MatMul_1361 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1360)\n",
      "  %onnx::MatMul_1362 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1336)\n",
      "  %onnx::Div_1363 = MatMul(%onnx::MatMul_1361, %onnx::MatMul_1362)\n",
      "  %onnx::Div_1364 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1365 = Div(%onnx::Div_1363, %onnx::Div_1364)\n",
      "  %attention_scores.43 = Add(%onnx::Add_1365, %onnx::Add_225)\n",
      "  %input.228 = Softmax[axis = 3](%attention_scores.43)\n",
      "  %onnx::Transpose_1368 = MatMul(%input.228, %onnx::MatMul_1350)\n",
      "  %onnx::Reshape_1369 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1368)\n",
      "  %onnx::MatMul_1377 = Reshape(%onnx::Reshape_1369, %onnx::Reshape_1724)\n",
      "  %onnx::Add_1379 = MatMul(%onnx::MatMul_1377, %onnx::MatMul_1725)\n",
      "  %input.232 = Add(%bert.encoder.layer.11.attention.output.dense.bias, %onnx::Add_1379)\n",
      "  %input.236 = Add(%input.232, %onnx::MatMul_1320)\n",
      "  %onnx::Sub_1382 = ReduceMean[axes = [-1]](%input.236)\n",
      "  %onnx::Pow_1383 = Sub(%input.236, %onnx::Sub_1382)\n",
      "  %onnx::Pow_1384 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1385 = Pow(%onnx::Pow_1383, %onnx::Pow_1384)\n",
      "  %onnx::Add_1386 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1385)\n",
      "  %onnx::Add_1387 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1388 = Add(%onnx::Add_1386, %onnx::Add_1387)\n",
      "  %onnx::Div_1389 = Sqrt(%onnx::Sqrt_1388)\n",
      "  %onnx::Mul_1390 = Div(%onnx::Pow_1383, %onnx::Div_1389)\n",
      "  %onnx::Add_1391 = Mul(%onnx::Mul_1390, %bert.encoder.layer.11.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1392 = Add(%onnx::Add_1391, %bert.encoder.layer.11.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1394 = MatMul(%onnx::MatMul_1392, %onnx::MatMul_1726)\n",
      "  %onnx::Div_1395 = Add(%bert.encoder.layer.11.intermediate.dense.bias, %onnx::Add_1394)\n",
      "  %onnx::Div_1396 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1397 = Div(%onnx::Div_1395, %onnx::Div_1396)\n",
      "  %onnx::Add_1398 = Erf(%onnx::Erf_1397)\n",
      "  %onnx::Add_1399 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1400 = Add(%onnx::Add_1398, %onnx::Add_1399)\n",
      "  %onnx::Mul_1401 = Mul(%onnx::Div_1395, %onnx::Mul_1400)\n",
      "  %onnx::Mul_1402 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1403 = Mul(%onnx::Mul_1401, %onnx::Mul_1402)\n",
      "  %onnx::Add_1405 = MatMul(%onnx::MatMul_1403, %onnx::MatMul_1727)\n",
      "  %input.240 = Add(%bert.encoder.layer.11.output.dense.bias, %onnx::Add_1405)\n",
      "  %input.244 = Add(%input.240, %onnx::MatMul_1392)\n",
      "  %onnx::Sub_1408 = ReduceMean[axes = [-1]](%input.244)\n",
      "  %onnx::Pow_1409 = Sub(%input.244, %onnx::Sub_1408)\n",
      "  %onnx::Pow_1410 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1411 = Pow(%onnx::Pow_1409, %onnx::Pow_1410)\n",
      "  %onnx::Add_1412 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1411)\n",
      "  %onnx::Add_1413 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1414 = Add(%onnx::Add_1412, %onnx::Add_1413)\n",
      "  %onnx::Div_1415 = Sqrt(%onnx::Sqrt_1414)\n",
      "  %onnx::Mul_1416 = Div(%onnx::Pow_1409, %onnx::Div_1415)\n",
      "  %onnx::Add_1417 = Mul(%onnx::Mul_1416, %bert.encoder.layer.11.output.LayerNorm.weight)\n",
      "  %onnx::Gather_1418 = Add(%onnx::Add_1417, %bert.encoder.layer.11.output.LayerNorm.bias)\n",
      "  %onnx::Gather_1419 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Gemm_1420 = Gather[axis = 1](%onnx::Gather_1418, %onnx::Gather_1419)\n",
      "  %onnx::Tanh_1421 = Gemm[alpha = 1, beta = 1, transB = 1](%onnx::Gemm_1420, %bert.pooler.dense.weight, %bert.pooler.dense.bias)\n",
      "  %input.248 = Tanh(%onnx::Tanh_1421)\n",
      "  %onnx::Gemm_1423 = Gemm[alpha = 1, beta = 1, transB = 1](%input.248, %dense_1.weight, %dense_1.bias)\n",
      "  %onnx::Gemm_1424 = Gemm[alpha = 1, beta = 1, transB = 1](%onnx::Gemm_1423, %dense_3.weight, %dense_3.bias)\n",
      "  %onnx::Sigmoid_1425 = Gemm[alpha = 1, beta = 1, transB = 1](%onnx::Gemm_1424, %dense_4.weight, %dense_4.bias)\n",
      "  %yhat = Sigmoid(%onnx::Sigmoid_1425)\n",
      "  return %yhat\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"rnn.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/ioachimlihor/Licenta/Project/licenta/notebooks/plot_model.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ioachimlihor/Licenta/Project/licenta/notebooks/plot_model.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39monnxruntime\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mort\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ioachimlihor/Licenta/Project/licenta/notebooks/plot_model.ipynb#ch0000008?line=2'>3</a>\u001b[0m ort_session \u001b[39m=\u001b[39m ort\u001b[39m.\u001b[39mInferenceSession(\u001b[39m\"\u001b[39m\u001b[39malexnet.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ioachimlihor/Licenta/Project/licenta/notebooks/plot_model.ipynb#ch0000008?line=4'>5</a>\u001b[0m outputs \u001b[39m=\u001b[39m ort_session\u001b[39m.\u001b[39mrun(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ioachimlihor/Licenta/Project/licenta/notebooks/plot_model.ipynb#ch0000008?line=5'>6</a>\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ioachimlihor/Licenta/Project/licenta/notebooks/plot_model.ipynb#ch0000008?line=6'>7</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mactual_input_1\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39m10\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)},\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ioachimlihor/Licenta/Project/licenta/notebooks/plot_model.ipynb#ch0000008?line=7'>8</a>\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(\"alexnet.onnx\")\n",
    "\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\"actual_input_1\": np.random.randn(10, 3, 224, 224).astype(np.float32)},\n",
    ")\n",
    "print(outputs[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "370c45c36568df420e0621ad65c468f2f5bbcd1be324cc5f2c0a2f77966e1542"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('licenta-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
